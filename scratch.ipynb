{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "mypath = os.getcwd() + '/tweet_dumper/'\n",
    "onlyfiles = [ f for f in listdir(mypath) if isfile(join(mypath,f)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet_files = [i for i in onlyfiles if i[-3:] == 'csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileName, fileExtension = os.path.splitext(onlyfiles[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient()\n",
    "db = client.legislation\n",
    "tweets = db.tweets\n",
    "combo = db.combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-3457d47f6e92>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-3457d47f6e92>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    #     print json.dumps(row)[:-1] + ', ' + json.dumps({\"handle\": tweet_files[0][:-11]})[1:]\u001b[0m\n\u001b[0m                                                                                              ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "csvfile = open(mypath+tweet_files[0], 'r')\n",
    "\n",
    "fieldnames = (\"id\",\"created_at\",\"text\",\"retweets\",\"favorites\")\n",
    "reader = csv.DictReader(csvfile, fieldnames)\n",
    "reader.next()\n",
    "for row in reader:\n",
    "#     print json.dumps(row)[:-1] + ', ' + json.dumps({\"handle\": tweet_files[0][:-11]})[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mypath = os.getcwd() + \"/congressional_data/sessions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'AnderCrenshaw_tweets.csv',\n",
       " 'BlumenauerMedia_tweets.csv',\n",
       " 'ChakaFattah_tweets.csv',\n",
       " 'ChuckGrassley_tweets.csv',\n",
       " 'Clyburn_tweets.csv',\n",
       " 'ConawayTX11_tweets.csv',\n",
       " 'CongCulberson_tweets.csv',\n",
       " 'CongressmanDan_tweets.csv',\n",
       " 'DesJarlaisTN04_tweets.csv',\n",
       " 'Farenthold_tweets.csv',\n",
       " 'GerryConnolly_tweets.csv',\n",
       " 'GKButterfield_tweets.csv',\n",
       " 'GrahamBlog_tweets.csv',\n",
       " 'GreggHarper_tweets.csv',\n",
       " 'HerreraBeutler_tweets.csv',\n",
       " 'InhofePress_tweets.csv',\n",
       " 'JasonInTheHouse_tweets.csv',\n",
       " 'JeffFlake_tweets.csv',\n",
       " 'JeffFortenberry_tweets.csv',\n",
       " 'JohnBoozman_tweets.csv',\n",
       " 'JohnCarneyde_tweets.csv',\n",
       " 'JohnCornyn_tweets.csv',\n",
       " 'JudgeCarter_tweets.csv',\n",
       " 'KeithEllison_tweets.csv',\n",
       " 'KenCalvert_tweets.csv',\n",
       " 'LuisGutierrez_tweets.csv',\n",
       " 'MarioDB_tweets.csv',\n",
       " 'MarkWarner_tweets.csv',\n",
       " 'MarshaBlackburn_tweets.csv',\n",
       " 'MartinHeinrich_tweets.csv',\n",
       " 'McCaskillOffice_tweets.csv',\n",
       " 'McConnellPress_tweets.csv',\n",
       " 'MichaelCBurgess_tweets.csv',\n",
       " 'MikeCrapo_tweets.csv',\n",
       " 'Randy_Forbes_tweets.csv',\n",
       " 'rep_tweet_history.py',\n",
       " 'RepAlGreen_tweets.csv',\n",
       " 'RepAndreCarson_tweets.csv',\n",
       " 'RepAndyHarrisMD_tweets.csv',\n",
       " 'RepAnnaEshoo_tweets.csv',\n",
       " 'RepBecerra_tweets.csv',\n",
       " 'RepBillFlores_tweets.csv',\n",
       " 'RepBobGibbs_tweets.csv',\n",
       " 'RepBoustany_tweets.csv',\n",
       " 'RepBrady_tweets.csv',\n",
       " 'RepChrisGibson_tweets.csv',\n",
       " 'RepChuck_tweets.csv',\n",
       " 'RepCicilline_tweets.csv',\n",
       " 'RepCleaver_tweets.csv',\n",
       " 'RepCohen_tweets.csv',\n",
       " 'RepCorrineBrown_tweets.csv',\n",
       " 'RepCuellar_tweets.csv',\n",
       " 'RepCummings_tweets.csv',\n",
       " 'RepDannyDavis_tweets.csv',\n",
       " 'RepDianaDeGette_tweets.csv',\n",
       " 'RepDianeBlack_tweets.csv',\n",
       " 'RepDonnaEdwards_tweets.csv',\n",
       " 'RepEliotEngel_tweets.csv',\n",
       " 'RepFincherTN08_tweets.csv',\n",
       " 'RepFitzpatrick_tweets.csv',\n",
       " 'RepFleming_tweets.csv',\n",
       " 'RepGaramendi_tweets.csv',\n",
       " 'RepGarrett_tweets.csv',\n",
       " 'RepGeneGreen_tweets.csv',\n",
       " 'RepGoodlatte_tweets.csv',\n",
       " 'RepGosar_tweets.csv',\n",
       " 'RepGusBilirakis_tweets.csv',\n",
       " 'RepGuthrie_tweets.csv',\n",
       " 'RepHartzler_tweets.csv',\n",
       " 'RepHastingsFL_tweets.csv',\n",
       " 'RepHensarling_tweets.csv',\n",
       " 'RepJeffDenham_tweets.csv',\n",
       " 'RepJeffDuncan_tweets.csv',\n",
       " 'RepJimCooper_tweets.csv',\n",
       " 'RepJimCosta_tweets.csv',\n",
       " 'RepJoeBarton_tweets.csv',\n",
       " 'RepJoeCourtney_tweets.csv',\n",
       " 'RepJoeCrowley_tweets.csv',\n",
       " 'RepJoeHeck_tweets.csv',\n",
       " 'RepJohnConyers_tweets.csv',\n",
       " 'RepJohnDuncanJr_tweets.csv',\n",
       " 'RepJudyChu_tweets.csv',\n",
       " 'RepKarenBass_tweets.csv',\n",
       " 'RepKayGranger_tweets.csv',\n",
       " 'RepKevinBrady_tweets.csv',\n",
       " 'RepLloydDoggett_tweets.csv',\n",
       " 'RepLoisCapps_tweets.csv',\n",
       " 'RepLouBarletta_tweets.csv',\n",
       " 'RepLouieGohmert_tweets.csv',\n",
       " 'RepMarciaFudge_tweets.csv',\n",
       " 'RepMGriffith_tweets.csv',\n",
       " 'RepMikeCoffman_tweets.csv',\n",
       " 'RepMoBrooks_tweets.csv',\n",
       " 'RepPeterDeFazio_tweets.csv',\n",
       " 'RepraulGrijalva_tweets.csv',\n",
       " 'RepReneeEllmers_tweets.csv',\n",
       " 'RepRichardHanna_tweets.csv',\n",
       " 'RepRickCrawford_tweets.csv',\n",
       " 'RepSamFarr_tweets.csv',\n",
       " 'RepSamGraves_tweets.csv',\n",
       " 'RepSeanDuffy_tweets.csv',\n",
       " 'RepSteveChabot_tweets.csv',\n",
       " 'RepSusanDavis_tweets.csv',\n",
       " 'RepTedDeutch_tweets.csv',\n",
       " 'RepTomGraves_tweets.csv',\n",
       " 'RepTrentFranks_tweets.csv',\n",
       " 'Robert_Aderholt_tweets.csv',\n",
       " 'RosaDeLauro_tweets.csv',\n",
       " 'RoyBlunt_tweets.csv',\n",
       " 'SanfordBishop_tweets.csv',\n",
       " 'Sen_JoeManchin_tweets.csv',\n",
       " 'SenAlexander_tweets.csv',\n",
       " 'SenatorBaldwin_tweets.csv',\n",
       " 'SenatorBoxer_tweets.csv',\n",
       " 'SenatorBurr_tweets.csv',\n",
       " 'SenatorCantwell_tweets.csv',\n",
       " 'SenatorCardin_tweets.csv',\n",
       " 'SenatorCarper_tweets.csv',\n",
       " 'SenatorCollins_tweets.csv',\n",
       " 'SenatorDurbin_tweets.csv',\n",
       " 'SenatorEnzi_tweets.csv',\n",
       " 'SenatorMenendez_tweets.csv',\n",
       " 'SenatorRisch_tweets.csv',\n",
       " 'SenatorSessions_tweets.csv',\n",
       " 'SenatorShaheen_tweets.csv',\n",
       " 'SenatorTester_tweets.csv',\n",
       " 'SenatorTomUdall_tweets.csv',\n",
       " 'SenatorWicker_tweets.csv',\n",
       " 'SenBennetCo_tweets.csv',\n",
       " 'SenBillNelson_tweets.csv',\n",
       " 'SenBlumenthal_tweets.csv',\n",
       " 'SenBobCasey_tweets.csv',\n",
       " 'SenBobCorker_tweets.csv',\n",
       " 'SenCapito_tweets.csv',\n",
       " 'SenCoonsOffice_tweets.csv',\n",
       " 'SenCoryGardner_tweets.csv',\n",
       " 'SenDanCoats_tweets.csv',\n",
       " 'SenDonnelly_tweets.csv',\n",
       " 'SenFeinstein_tweets.csv',\n",
       " 'SenJackReed_tweets.csv',\n",
       " 'SenJeffMerkley_tweets.csv',\n",
       " 'SenJohnBarrasso_tweets.csv',\n",
       " 'SenOrrinHatch_tweets.csv',\n",
       " 'SenPatRoberts_tweets.csv',\n",
       " 'SenSanders_tweets.csv',\n",
       " 'SenSherrodBrown_tweets.csv',\n",
       " 'SenStabenow_tweets.csv',\n",
       " 'SenThadCochran_tweets.csv',\n",
       " 'SenWhitehouse_tweets.csv',\n",
       " 'SpeakerBoehner_tweets.csv',\n",
       " 'TGowdySC_tweets.csv',\n",
       " 'TomColeOK04_tweets.csv',\n",
       " 'tweet_dumper.py',\n",
       " 'tweet_dumper.pyc',\n",
       " 'USRepKCastor_tweets.csv',\n",
       " 'USRepMikeDoyle_tweets.csv',\n",
       " 'USRepRodney_tweets.csv',\n",
       " 'VernBuchanan_tweets.csv',\n",
       " 'VirginiaFoxx_tweets.csv',\n",
       " 'YvetteClarke_tweets.csv']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ f for f in listdir(mypath) if isfile(join(mypath,f)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/amangum/Projects/metis/text_processing (fletcher)/congressional_data/sessions/103\n",
      "/Users/amangum/Projects/metis/text_processing (fletcher)/congressional_data/sessions/104\n",
      "/Users/amangum/Projects/metis/text_processing (fletcher)/congressional_data/sessions/105\n",
      "/Users/amangum/Projects/metis/text_processing (fletcher)/congressional_data/sessions/106\n",
      "/Users/amangum/Projects/metis/text_processing (fletcher)/congressional_data/sessions/107\n",
      "/Users/amangum/Projects/metis/text_processing (fletcher)/congressional_data/sessions/108\n",
      "/Users/amangum/Projects/metis/text_processing (fletcher)/congressional_data/sessions/109\n",
      "/Users/amangum/Projects/metis/text_processing (fletcher)/congressional_data/sessions/110\n",
      "/Users/amangum/Projects/metis/text_processing (fletcher)/congressional_data/sessions/111\n",
      "/Users/amangum/Projects/metis/text_processing (fletcher)/congressional_data/sessions/112\n",
      "/Users/amangum/Projects/metis/text_processing (fletcher)/congressional_data/sessions/113\n",
      "/Users/amangum/Projects/metis/text_processing (fletcher)/congressional_data/sessions/114\n"
     ]
    }
   ],
   "source": [
    "for f in listdir(mypath):\n",
    "    if isdir(join(mypath,f)):\n",
    "        session = mypath + f\n",
    "        print session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e4a2a36015c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdirs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"text-versions\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#         text_string = \"{'text_versions': \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtext_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/text-versions/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "for index, (root, dirs, files) in enumerate(os.walk(session)):\n",
    "    if dirs == [\"text-versions\"]:\n",
    "#         text_string = \"{'text_versions': \"\n",
    "        text_dict = {}\n",
    "        for version in listdir(root + '/text-versions/'):\n",
    "            doc_path = root + '/text-versions/' + version + '/document.txt'\n",
    "            with open(doc_path, 'rb') as f:\n",
    "                text = f.read()\n",
    "#             text_string += \", '{0}': '{1}'\".format(version, text)\n",
    "            text_dict.update({version: 'text'})\n",
    "        print text_dict\n",
    "        with open(root + '/data.json', 'rb') as j:\n",
    "            json_data = json.load(j)\n",
    "        print json_data\n",
    "#         mongo_save = json_data[:-1] + ', ' + text_string[1:] + '}'\n",
    "#         print mongo_save\n",
    "        print(\"saving: \", root)\n",
    "#         # bills.insert(mongo_save)\n",
    "#     if root[:94] == session + \"/votes\":\n",
    "#         for file in files:\n",
    "#             if file == 'data.json':\n",
    "#                 print root + '/' + file\n",
    "#                 with open(root + '/' + file, 'rb') as j:\n",
    "#                     votes.insert(j)\n",
    "                \n",
    "\n",
    "\n",
    "    if index == 20: break\n",
    "# for root, dirs, files in os.walk(mypath):\n",
    "#     for file in files:\n",
    "#         if file.endswith(\".txt\"):\n",
    "#              print(os.path.join(root, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import join, isdir, isfile\n",
    "import json\n",
    "\n",
    "\n",
    "client = MongoClient()\n",
    "db = client.legislation\n",
    "bills = db.bills\n",
    "votes = db.votes\n",
    "\n",
    "mypath = os.getcwd() + \"/congressional_data/sessions/\"\n",
    "\n",
    "\n",
    "def get_sessions():\n",
    "    sessions = []\n",
    "    for f in listdir(mypath):\n",
    "        if isdir(join(mypath, f)):\n",
    "            sessions.append(mypath + f)\n",
    "    return sessions\n",
    "\n",
    "\n",
    "def remove_dot_key(obj):\n",
    "    for key in obj.keys():\n",
    "        new_key = key.replace(\".\",\"\")\n",
    "        if new_key != key:\n",
    "            obj[new_key] = obj[key]\n",
    "            del obj[key]\n",
    "    return obj\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "def dear_mongo():\n",
    "    sessions = get_sessions()\n",
    "    for session in sessions:\n",
    "        for index, (root, dirs, files) in enumerate(os.walk(session)):\n",
    "            if index == 200: break\n",
    "            if dirs == [\"text-versions\"]:\n",
    "                \n",
    "                if isfile(root + '/data.json'):\n",
    "                    text_dict = {}\n",
    "#                     print (root + ('/text-versions/' + 'ih'))\n",
    "                    print [f for f in listdir(root + '/text-versions/') if isdir(join('/text-versions/', f)) ]\n",
    "                    for version in [f for f in listdir(root + '/text-versions/') if isdir(join(mypath,f)) ]:\n",
    "                        doc_path = root + '/text-versions/' + version + '/document.txt'\n",
    "                        if isfile(doc_path):\n",
    "                            with open(doc_path) as f:\n",
    "                                text = f.read()\n",
    "                            text_dict.update({version: text})\n",
    "                    with open(root + '/data.json') as j:\n",
    "                        json_data = json.load(j)\n",
    "                    json_data.update({'text_versions': text_dict})\n",
    "                    bills.save(json_data)\n",
    "#             if '/votes' in root:\n",
    "#                 for file in files:\n",
    "#                     if file == 'data.json':\n",
    "#                         print('saving: ' + root + '/' + file)\n",
    "#                         with open(root + '/' + file) as j:\n",
    "#                             j = json.load(j, object_hook=remove_dot_key)\n",
    "#                             try:\n",
    "#                                 votes.save(j)\n",
    "#                             except:\n",
    "#                                 print \"except!\"\n",
    "\n",
    "       \n",
    "\n",
    "dear_mongo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get half pass and half failed bills\n",
    "import pandas as pd\n",
    "cursor = combo.find({\"subjects_top_term\": {\"$exists\": \"true\"}}, {\"_id\": 0},\n",
    "                     no_cursor_timeout=True, limit=2000)\n",
    "titles, texts, categories, congress, bill_type, number, subject_top, subjects, sponsor,\\\n",
    "    requires, result = zip(*[(i['official_title'], i[\"text_versions\"].itervalues().next(),\n",
    "                                i[\"category\"], i[\"congress\"], i[\"bill_type\"], i[\"number\"],\n",
    "                                i[\"subjects_top_term\"], i[\"subjects\"], i[\"sponsor\"], i[\"requires\"],\n",
    "                                i[\"result\"]) for i in cursor])\n",
    "bills = {'title': titles, 'vote': result, 'text': texts, 'sponsor': sponsor,\n",
    "            \"subject_top\": subject_top, \"subjects\": subjects, 'category': categories,\n",
    "            'congress': congress, 'bill_type': bill_type, 'number': number, 'requires': requires}\n",
    "df = pd.DataFrame(bills, columns=['vote', 'title', 'sponsor', 'subject_top',\n",
    "                                    'subjects', 'category', 'requires', 'text'])\n",
    "df['Passed'] = pd.get_dummies(df['vote'])['Passed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 2, 5, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 49, 51, 56, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 83, 84, 85, 86, 88, 89, 91, 92, 93, 95, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 121, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, ...], dtype='int64')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Passed == 1].index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "failed = df[df.Passed == 0]\n",
    "passed = df[df.Passed == 1].ix[random.sample(df[df.Passed == 1].index, failed.Passed.count())]\n",
    "df = passed.append(failed).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor = combo.find({\"subjects_top_term\": {\"$exists\": \"true\"}}, {\"_id\": 0},\n",
    "                     no_cursor_timeout=True, limit=5000)\n",
    "df = pd.DataFrame()\n",
    "for i in cursor:\n",
    "    df = df.append(i, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_type</th>\n",
       "      <th>category</th>\n",
       "      <th>congress</th>\n",
       "      <th>cosponsors</th>\n",
       "      <th>number</th>\n",
       "      <th>official_title</th>\n",
       "      <th>requires</th>\n",
       "      <th>result</th>\n",
       "      <th>sponsor</th>\n",
       "      <th>subjects</th>\n",
       "      <th>subjects_top_term</th>\n",
       "      <th>summary</th>\n",
       "      <th>text_versions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hr</td>\n",
       "      <td>passage</td>\n",
       "      <td>105</td>\n",
       "      <td>[{u'withdrawn_at': None, u'name': u'Aderholt, ...</td>\n",
       "      <td>4300</td>\n",
       "      <td>To support enhanced drug interdiction efforts ...</td>\n",
       "      <td>1/2</td>\n",
       "      <td>Passed</td>\n",
       "      <td>{u'name': u'McCollum, Bill', u'district': u'8'...</td>\n",
       "      <td>[Africa (Sub-Saharan), Agricultural research, ...</td>\n",
       "      <td>International affairs</td>\n",
       "      <td>{u'date': u'1998-09-16', u'text': u'TABLE OF C...</td>\n",
       "      <td>{u'rfs': u'\n",
       "[Congressional Bills 105th Congres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hr</td>\n",
       "      <td>amendment</td>\n",
       "      <td>105</td>\n",
       "      <td>[{u'withdrawn_at': None, u'name': u'Ballenger,...</td>\n",
       "      <td>4550</td>\n",
       "      <td>To provide for programs to facilitate a signif...</td>\n",
       "      <td>1/2</td>\n",
       "      <td>Failed</td>\n",
       "      <td>{u'name': u'Portman, Rob', u'district': u'2', ...</td>\n",
       "      <td>[Administrative procedure, Agriculture and foo...</td>\n",
       "      <td>Health</td>\n",
       "      <td>{u'date': u'1998-09-16', u'text': u'TABLE OF C...</td>\n",
       "      <td>{u'ih': u'\n",
       "[Congressional Bills 105th Congress...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hr</td>\n",
       "      <td>passage</td>\n",
       "      <td>105</td>\n",
       "      <td>[{u'withdrawn_at': None, u'name': u'Ballenger,...</td>\n",
       "      <td>4550</td>\n",
       "      <td>To provide for programs to facilitate a signif...</td>\n",
       "      <td>1/2</td>\n",
       "      <td>Passed</td>\n",
       "      <td>{u'name': u'Portman, Rob', u'district': u'2', ...</td>\n",
       "      <td>[Administrative procedure, Agriculture and foo...</td>\n",
       "      <td>Health</td>\n",
       "      <td>{u'date': u'1998-09-16', u'text': u'TABLE OF C...</td>\n",
       "      <td>{u'ih': u'\n",
       "[Congressional Bills 105th Congress...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hr</td>\n",
       "      <td>amendment</td>\n",
       "      <td>105</td>\n",
       "      <td>[{u'withdrawn_at': None, u'name': u'Bereuter, ...</td>\n",
       "      <td>1432</td>\n",
       "      <td>To authorize a new trade and investment policy...</td>\n",
       "      <td>1/2</td>\n",
       "      <td>Failed</td>\n",
       "      <td>{u'name': u'Crane, Philip M.', u'district': u'...</td>\n",
       "      <td>[AIDS (Disease), Africa (Sub-Saharan), Agribus...</td>\n",
       "      <td>International affairs</td>\n",
       "      <td>{u'date': u'1998-03-11', u'text': u'African Gr...</td>\n",
       "      <td>{u'ih': u'\n",
       "[Congressional Bills 105th Congress...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hr</td>\n",
       "      <td>recommit</td>\n",
       "      <td>105</td>\n",
       "      <td>[{u'withdrawn_at': None, u'name': u'Bereuter, ...</td>\n",
       "      <td>1432</td>\n",
       "      <td>To authorize a new trade and investment policy...</td>\n",
       "      <td>1/2</td>\n",
       "      <td>Failed</td>\n",
       "      <td>{u'name': u'Crane, Philip M.', u'district': u'...</td>\n",
       "      <td>[AIDS (Disease), Africa (Sub-Saharan), Agribus...</td>\n",
       "      <td>International affairs</td>\n",
       "      <td>{u'date': u'1998-03-11', u'text': u'African Gr...</td>\n",
       "      <td>{u'ih': u'\n",
       "[Congressional Bills 105th Congress...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bill_type   category congress  \\\n",
       "0        hr    passage      105   \n",
       "1        hr  amendment      105   \n",
       "2        hr    passage      105   \n",
       "3        hr  amendment      105   \n",
       "4        hr   recommit      105   \n",
       "\n",
       "                                          cosponsors number  \\\n",
       "0  [{u'withdrawn_at': None, u'name': u'Aderholt, ...   4300   \n",
       "1  [{u'withdrawn_at': None, u'name': u'Ballenger,...   4550   \n",
       "2  [{u'withdrawn_at': None, u'name': u'Ballenger,...   4550   \n",
       "3  [{u'withdrawn_at': None, u'name': u'Bereuter, ...   1432   \n",
       "4  [{u'withdrawn_at': None, u'name': u'Bereuter, ...   1432   \n",
       "\n",
       "                                      official_title requires  result  \\\n",
       "0  To support enhanced drug interdiction efforts ...      1/2  Passed   \n",
       "1  To provide for programs to facilitate a signif...      1/2  Failed   \n",
       "2  To provide for programs to facilitate a signif...      1/2  Passed   \n",
       "3  To authorize a new trade and investment policy...      1/2  Failed   \n",
       "4  To authorize a new trade and investment policy...      1/2  Failed   \n",
       "\n",
       "                                             sponsor  \\\n",
       "0  {u'name': u'McCollum, Bill', u'district': u'8'...   \n",
       "1  {u'name': u'Portman, Rob', u'district': u'2', ...   \n",
       "2  {u'name': u'Portman, Rob', u'district': u'2', ...   \n",
       "3  {u'name': u'Crane, Philip M.', u'district': u'...   \n",
       "4  {u'name': u'Crane, Philip M.', u'district': u'...   \n",
       "\n",
       "                                            subjects      subjects_top_term  \\\n",
       "0  [Africa (Sub-Saharan), Agricultural research, ...  International affairs   \n",
       "1  [Administrative procedure, Agriculture and foo...                 Health   \n",
       "2  [Administrative procedure, Agriculture and foo...                 Health   \n",
       "3  [AIDS (Disease), Africa (Sub-Saharan), Agribus...  International affairs   \n",
       "4  [AIDS (Disease), Africa (Sub-Saharan), Agribus...  International affairs   \n",
       "\n",
       "                                             summary  \\\n",
       "0  {u'date': u'1998-09-16', u'text': u'TABLE OF C...   \n",
       "1  {u'date': u'1998-09-16', u'text': u'TABLE OF C...   \n",
       "2  {u'date': u'1998-09-16', u'text': u'TABLE OF C...   \n",
       "3  {u'date': u'1998-03-11', u'text': u'African Gr...   \n",
       "4  {u'date': u'1998-03-11', u'text': u'African Gr...   \n",
       "\n",
       "                                       text_versions  \n",
       "0  {u'rfs': u'\n",
       "[Congressional Bills 105th Congres...  \n",
       "1  {u'ih': u'\n",
       "[Congressional Bills 105th Congress...  \n",
       "2  {u'ih': u'\n",
       "[Congressional Bills 105th Congress...  \n",
       "3  {u'ih': u'\n",
       "[Congressional Bills 105th Congress...  \n",
       "4  {u'ih': u'\n",
       "[Congressional Bills 105th Congress...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = test.append([{'vote': 2, 'text': 'words'}], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.text_versions =  df.text_versions.apply(lambda x: x.itervalues().next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.result.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
