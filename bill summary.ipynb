{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import nltk\n",
    "import string\n",
    "from progressbar import ProgressBar\n",
    "from pymongo import MongoClient\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db = client.legislation\n",
    "bills = db.bills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('all_bills.pickle', 'rb') as f:\n",
    "    bills_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bills_dict='clear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-cd2c202f8557>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# downsized = random.sample(bills_dict.items(), 5000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mone_bill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbills_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# get bill_id and raw text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbill_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_bill\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_bill\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "# downsized = random.sample(bills_dict.items(), 5000)\n",
    "one_bill = random.choice(bills_dict.items())\n",
    "# get bill_id and raw text\n",
    "bill_id = one_bill[0]\n",
    "text = one_bill[1]\n",
    "print bill_id\n",
    "print text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'SECTION 1.', u'section 5142.']\n",
      "[u'(IH)', u'(a)', u'(1)', u'(2)', u'(3)', u'(b)', u'(1)', u'(2)', u'(A)', u'(i)', u'(B)', u'(ii)', u'(1)', u'(ii)', u'(1)', u'(i)', u'(B)', u'(i)', u'(ii)', u'(1)', u'(A)(i)', u'(I)', u'(II)', u'(b)', u'(ii)', u'(i)', u'(c)', u'(1)', u'(A)', u'(2)', u'(2)))', u'(B)', u'(2)', u'(1)', u'(d)(2)(B)', u'(A)', u'(B)', u'(d)(2)(A)(iii)', u'(d)', u'(1)', u'(2)', u'(A)', u'(i)', u'(ii)', u'(iii)', u'(B)', u'(i)', u'(ii)', u'(ii)', u'(iii)', u'(A)', u'(ii)', u'(A)(iii)', u'(C)', u'(B)', u'(i)', u'(ii)', u'(iii)', u'(3)', u'(4)', u'(A)', u'(B)', u'(B)', u'(e)', u'(1)', u'(a)(2)', u'(2)', u'(A)', u'(B)', u'(3)', u'(f)', u'(g)', u'(h)', u'(i)', u'(j)', u'(1)', u'(2)', u'(A)', u'(B)', u'(i)', u'(ii)', u'(I)', u'(II)']\n"
     ]
    }
   ],
   "source": [
    "def remove_boilerplate(text):\n",
    "    #remove following\n",
    "    '''\n",
    "    'SEC. ###.'\n",
    "    \"section 'word'\"\n",
    "    \"subsection 'word''\n",
    "    'described/under/established in section (b)\"\n",
    "    'described in subsection (b)\"\n",
    "    'described in paragraph(s)/clause(s)/subparagraph(s)/subclause(s) (b)\"\n",
    "    'subject to ...'\n",
    "    'in accordance with'\n",
    "    'under section ....'\n",
    "    'described in the appropriate provisions of'\n",
    "    'in carrying out'\n",
    "    \"u'_______________________________________________________________________'\"\n",
    "    'everything before the line and one line after'\n",
    "    '<all>'\n",
    "    #replace\n",
    "    \"'--' with ' '\"\n",
    "    \"`` with ''\"\n",
    "    '''\n",
    "    \n",
    "    # '/section\\s\\d+\\./i'\n",
    "    print re.findall(r'section\\s\\d*\\.', text, re.I) # 'SECTION(.) ###.'\n",
    "    print re.findall(r'\\(\\S*\\)', text,re.I) # 'blank(char)blank'\n",
    "    r'(under\\s)?section\\.?\\s\\d+\\.?(\\(\\S*\\))?' #combo\n",
    "    r'((described|established)\\s(in|under)|(subject\\sto)|(in\\saccordance\\swith))(\\sthe\\sappropriate\\sprovisions\\sof)?\\s(section|subsection|paragraph|subparagraph|clause|subclause)'\n",
    "    \n",
    "remove_boilerplate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SECTION 1.; Section 1501; Section 1503(c); Section 1504(d); section\n",
      "5332; section 1513; Section 1502; section 1501(b); Section 1503(a);\n",
      "Section 1513; section 1505; section 1502(a); section 1502; Section\n",
      "1507(b); Section 1509; section only; section is; section in\n",
      "None\n",
      "(a); (A); (c); (B); (2); (A); (B); (2); (3); (3); (C); (1); (1); (3);\n",
      "(A); (A); (B); (4); (1); (b); (A); (i); (ii); (B); (b); (C); (a); (a);\n",
      "(D); (b); (2); (3); (A); (B); (c); (b); (1)(B); (1); (d); (1); (e);\n",
      "(2); (d); (a); (e); (f); (A); (c); (B); (b); (b); (a); (2)(A); (B)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "tokens = WhitespaceTokenizer().tokenize(text)\n",
    "# tokens.findall(r'')\n",
    "# tokens\n",
    "x= nltk.Text(tokens)\n",
    "print x.findall(r\"<section> <.*> (?i)\")\n",
    "print x.findall(r\"<\\(.*\\)>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get custom sentence tokenizer\n",
    "with open('sentence_tokenizer_113_114.pickle', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Congressional Bills 109th Congress]\n",
      "[From the U.S. Government Printing Office]\n",
      "[H.R. 5577 Introduced in House (IH)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "109th CONGRESS\n",
      "  2d Session\n",
      "                                H. R. 5577\n",
      "\n",
      "To enhance protection of records of the Department of Veterans Affairs \n",
      "containing personal identifying information that is required by law to \n",
      "be confidential and privileged from disclosure except as authorized by \n",
      "                                  law.\n",
      "***\n",
      "_______________________________________________________________________\n",
      "\n",
      "\n",
      "                    IN THE HOUSE OF REPRESENTATIVES\n",
      "\n",
      "                              June 9, 2006\n",
      "\n",
      " Mrs. Capito introduced the following bill; which was referred to the \n",
      "                     Committee on Veterans' Affairs\n",
      "\n",
      "_______________________________________________________________________\n",
      "\n",
      "                                 A BILL\n",
      "\n",
      "\n",
      " \n",
      "To enhance protection of records of the Department of Veterans Affairs \n",
      "containing personal identifying information that is required by law to \n",
      "be confidential and privileged from disclosure except as authorized by \n",
      "                                  law.\n",
      "***\n",
      "Be it enacted by the Senate and House of Representatives of the \n",
      "United States of America in Congress assembled,\n",
      "\n",
      "SECTION 1. SHORT TITLE.\n",
      "***\n",
      "This Act may be cited as the ``Veterans Identity Protection Act of \n",
      "2006''.\n",
      "***\n",
      "SEC.\n",
      "***\n",
      "2. SENSE OF CONGRESS.\n",
      "***\n",
      "It is the sense of Congress that--\n",
      "            (1) the Department of Veterans Affairs is responsible by \n",
      "        law for safeguarding and holding confidential the records of \n",
      "        the Department that contain personal identifying information \n",
      "        about present and former members of the Armed Forces and their \n",
      "        family members; and\n",
      "            (2) it is the responsibility of the Department when such \n",
      "        identifying information is lost or compromised due to the \n",
      "        carelessness of the Department or its employees to assist those \n",
      "        individuals whose identifying information is affected in \n",
      "        mitigating any affect of that loss or compromise.\n",
      "***\n",
      "SEC.\n",
      "***\n",
      "3.\n",
      "***\n",
      "OFFICE OF IDENTITY PROTECTION IN DEPARTMENT OF VETERANS \n",
      "              AFFAIRS.\n",
      "***\n",
      "(a) Establishment.--There is established within the Department of \n",
      "Veterans Affairs an Office of Identity Protection.\n",
      "***\n",
      "The Office shall be \n",
      "administered by a Director who shall be appointed by the Secretary.\n",
      "***\n",
      "(b) Purpose.--The purpose of the Office shall be--\n",
      "            (1) to prevent the loss or compromise of personal \n",
      "        identifying information (including name, social security \n",
      "        number, financial records, and health records) about present \n",
      "        and former members of the Armed Forces and their family members \n",
      "        that is required by section 5701 of title 38, United States \n",
      "        Code, or any other provision of law to be held confidential and \n",
      "        privileged and protected from disclosure except as authorized \n",
      "        by law; and\n",
      "            (2) to assist any person whose personal identifying \n",
      "        information referred to in paragraph (1) is or may have been \n",
      "        compromised by the Department or a Department employee in \n",
      "        mitigating the effect of any such compromise.\n",
      "***\n",
      "(c) Responsibilities.--The Secretary of Veterans Affairs, acting \n",
      "through the Office of Veterans Identity Protection, shall--\n",
      "            (1) whenever there is a loss or compromise of personal \n",
      "        identifying information described in subsection (b)(1), notify \n",
      "        each individual whose personal identifying information was lost \n",
      "        or compromised of that loss or compromise;\n",
      "            (2) contract with national credit reporting agencies to \n",
      "        provide one credit report every six months for three years, \n",
      "        without charge to the recipient, to any individual whose \n",
      "        personal identifying information held by the Department of \n",
      "        Veterans Affairs is or may have compromised due to the \n",
      "        carelessness of the Department or its employees in violation of \n",
      "        section 5701 of title 38, United States Code, or any other \n",
      "        provision of law;\n",
      "            (3) offer a 24-hour toll-free telephone number and a \n",
      "        website for individuals described in paragraph (2) to provide \n",
      "        them information regarding access to credit reporting services;\n",
      "            (4) work in coordination with the Department of Defense and \n",
      "        the Federal Trade Commission to ensure that active-duty \n",
      "        military personnel, especially those deployed in combat zones, \n",
      "        have access to credit reporting services; and\n",
      "            (5) make available to present and former members of the \n",
      "        Armed Forces and their family members, through internet web \n",
      "        pages, outreach activities, and other appropriate means, \n",
      "        information on possible fraudulent consumer credit or reporting \n",
      "        services that may be aimed at present or former members of the \n",
      "        Armed Forces.\n",
      "***\n",
      "(d) Agencies to Be Notified.--The Office shall be responsible for \n",
      "ensuring that the Department of Justice and the Federal Trade \n",
      "Commission are notified immediately when the Department of Veterans \n",
      "Affairs knows or suspects that personal data in the records of the \n",
      "Department have been compromised.\n",
      "***\n",
      "SEC.\n",
      "***\n",
      "4.\n",
      "***\n",
      "INSPECTOR GENERAL REPORT ON DATA SECURITY PRACTICES OF \n",
      "              DEPARTMENT OF VETERANS AFFAIRS.\n",
      "***\n",
      "(a) Study.--The Inspector General of the Department of Veterans \n",
      "Affairs shall conduct a study of the data security practices of the \n",
      "Department, including practices relating to access to personal \n",
      "identifying information held by the Department and the authorization \n",
      "process for removing such data from secure custody in the files of the \n",
      "Department.\n",
      "***\n",
      "(b) Report.--Not later than six months after the date of the \n",
      "enactment of this Act, the Inspector General shall submit to the \n",
      "Committees on Veterans' Affairs of the Senate and the House of \n",
      "Representatives a report providing the results of the study under \n",
      "subsection (a).\n",
      "***\n",
      "SEC.\n",
      "***\n",
      "5.\n",
      "***\n",
      "CRIMINAL PENALTY.\n",
      "***\n",
      "Any officer or employee of the Department of Veterans Affairs who, \n",
      "except as authorized by law or by the Secretary of Veterans Affairs, \n",
      "removes from the custody of the Department of Veterans Affairs any \n",
      "file, record, report, or document of the Department of Veterans Affairs \n",
      "that is subject to section 5701 of title 38, United States Code, shall \n",
      "be fined as provided in title 18, United States Code, or imprisoned not \n",
      "more than 2 years, or both.\n",
      "***\n",
      "<all>\n",
      "\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "for i in sentences:\n",
    "    print i\n",
    "    print '***'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-919f12b63c6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msublinear_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlowercase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/amangum/Virtualenvs/metis/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1283\u001b[0m             \u001b[0mTf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0midf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \"\"\"\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amangum/Virtualenvs/metis/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 804\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amangum/Virtualenvs/metis/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n\u001b[0m\u001b[1;32m    752\u001b[0m                                  \" contain stop words\")\n\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, stop_words='english', ngram_range=(1,3), lowercase=True)\n",
    "docs = vectorizer.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'unicode' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3a02a8260e0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'unicode' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "# six concepts seems reasonable for each bill so clustering on that\n",
    "\n",
    "stem beforehand"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
